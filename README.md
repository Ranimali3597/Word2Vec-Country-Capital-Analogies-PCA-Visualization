Word2Vec Country–Capital Analogies & PCA Visualization

This project demonstrates how word embeddings capture semantic relationships between words using the Google News Word2Vec model. It focuses on:

✔ Extracting a subset of word embeddings

✔ Performing vector analogies (e.g., king − man + woman = queen)

✔ Predicting countries using city–country analogy logic

✔ Measuring accuracy

✔ Applying PCA to reduce 300-dim vectors to 2D

✔ Visualizing word clusters in a scatter plot
